{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a6b20c",
   "metadata": {},
   "source": [
    "# Career Agent Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db63d7ca",
   "metadata": {},
   "source": [
    "### Parsing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c82301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pypdf import PdfReader\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "def parse_web_page(profile_url):\n",
    "    response = requests.get(profile_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    content = soup.get_text(strip=True, separator=' ')\n",
    "    return content\n",
    "\n",
    "def parse_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    content = \"\"\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            content += text\n",
    "    return content\n",
    "\n",
    "def parse_text(text_path):\n",
    "    with open(text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "def parse_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5f4e7",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b818edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_content(doc, separators):\n",
    "    # split the document into parts using the separators\n",
    "    pattern = f\"({'|'.join(re.escape(sep) for sep in separators)})\"\n",
    "    docs = re.split(pattern, doc)\n",
    "    parts = [doc.strip() for doc in docs if doc.strip()]\n",
    "    return parts\n",
    "\n",
    "def combine_parts(parts, separators):\n",
    "    combined_docs = []\n",
    "    for i in range(len(parts)):\n",
    "        if parts[i] in separators:\n",
    "            combined_docs.append(parts[i] + \": \" + parts[i+1])\n",
    "            i += 1\n",
    "    return combined_docs\n",
    "\n",
    "def drop_parts(parts, separators):\n",
    "    return [part for part in parts if part not in separators]\n",
    "\n",
    "def split_fixed_size(text, size):\n",
    "    return [text[i:i+size] for i in range(0, len(text), size)]\n",
    "\n",
    "def beatiful_print(subject, content):\n",
    "    print(\"===============================\")\n",
    "    print(subject)\n",
    "    print(\"===============================\")\n",
    "    for sent in content.split('.'):\n",
    "        print(sent)\n",
    "    print(\"===============================\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466eb3b4",
   "metadata": {},
   "source": [
    "### Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc4a4959",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_url = \"https://mohamedmurad.github.io/\"\n",
    "linkedin_path = \"Mohamed Murad Data/linkedin.pdf\"\n",
    "summary_path = \"Mohamed Murad Data/summary.txt\"\n",
    "resume_path = \"Mohamed Murad Data/resume.pdf\"\n",
    "\n",
    "profile_content = parse_web_page(profile_url)\n",
    "linkedin_content = parse_pdf(linkedin_path)\n",
    "summary_content = parse_text(summary_path)\n",
    "resume_content = parse_pdf(resume_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94153582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beatiful_print(\"Profile Content: \", profile_content)\n",
    "# beatiful_print(\"Linkedin Content: \", linkedin_content)\n",
    "# beatiful_print(\"Summary Content: \", summary_content)\n",
    "# beatiful_print(\"Resume Content: \", resume_content)\n",
    "# print(len(profile_content))\n",
    "# print(len(linkedin_content))\n",
    "# print(len(summary_content))\n",
    "# print(len(resume_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01d72f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = ['Summary', 'Contact', 'Education', 'Experience', 'Skills', 'Projects', 'Certifications', 'Certificates', 'Publications', 'Awards', 'Patents', 'Other']\n",
    "subsections = ['Eventum Solutions', 'Alinma Bank', 'Communications, Space & Technology Commission (CST)', 'Arab National Bank', 'EJADA', 'Ejada Systems', 'Neoleap:', 'Ministry of Human Resources and Social Development', 'Ministry of Human Resources and Social Development - KSA', 'Zakat, Tax and Customs Authority', 'Eventum IT Solutions', 'Alexandria University']\n",
    "special_chars = ['.']\n",
    "fixed_size_split = 1000\n",
    "\n",
    "docs = []\n",
    "\n",
    "# 1. Profile\n",
    "docs.extend(drop_parts(split_content(profile_content, special_chars), special_chars))\n",
    "\n",
    "# 2. Linkedin\n",
    "docs.extend(combine_parts(split_content(linkedin_content, sections), sections))\n",
    "docs.extend(combine_parts(split_content(linkedin_content, subsections), subsections))\n",
    "docs.extend(split_fixed_size(linkedin_content, fixed_size_split))\n",
    "docs.extend(drop_parts(split_content(linkedin_content, special_chars), special_chars))\n",
    "\n",
    "# 3. Resume\n",
    "docs.extend(combine_parts(split_content(resume_content, sections), sections))\n",
    "docs.extend(combine_parts(split_content(resume_content, subsections), subsections))\n",
    "docs.extend(split_fixed_size(resume_content, fixed_size_split))\n",
    "docs.extend(drop_parts(split_content(resume_content, special_chars), special_chars))\n",
    "\n",
    "# 4. Summary\n",
    "docs.extend(drop_parts(split_content(summary_content, special_chars), special_chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57e1cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in docs:\n",
    "#     print(doc, \"\\n==========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4060204",
   "metadata": {},
   "source": [
    "### LLM models Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f64e083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "ai_client = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "deepseek_model_name = \"deepseek-r1:1.5b\"\n",
    "qwen_model_name = \"qwen3:0.6b\"\n",
    "llama_model_name = \"tinyllama:latest\"\n",
    "embedding_model_name = \"all-minilm:22m\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fcc97f",
   "metadata": {},
   "source": [
    "### Storing Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3195afa8",
   "metadata": {},
   "source": [
    "##### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0cc94cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(docs):\n",
    "    embeddings = []\n",
    "    for doc in docs:\n",
    "        emb = ai_client.embeddings.create(model=embedding_model_name, input=doc)\n",
    "        embeddings.append(emb)\n",
    "    return embeddings\n",
    "\n",
    "def extract_embedding_list(embeddings):\n",
    "    embeddings_data = [embeddings[i].data[0].embedding for i in range(len(embeddings))]\n",
    "    return embeddings_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6cf3d9",
   "metadata": {},
   "source": [
    "##### Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68716586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "def create_chroma_collection(db_name):\n",
    "    client = chromadb.Client()\n",
    "    client.delete_collection(db_name) if db_name in [c.name for c in client.list_collections()] else None\n",
    "    collection = client.create_collection(name=db_name)\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f2a0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"career_agent_db\"\n",
    "\n",
    "# step 1: create the collection\n",
    "collection = create_chroma_collection(db_name)\n",
    "\n",
    "# step 2: get the embeddings\n",
    "embeddings = get_embedding(docs)\n",
    "embeddings_data = extract_embedding_list(embeddings)\n",
    "\n",
    "# step 3: store the embeddings in the collection\n",
    "collection.add(documents=docs, embeddings=embeddings_data, ids=[f\"doc_{i}\" for i in range(len(docs))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f56a7",
   "metadata": {},
   "source": [
    "##### Test Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec60e33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: tell me about your experience at Alinma Bank\n",
      "Top matches:\n",
      "Alinma Bank\n",
      "Artificial Intelligence Engineer\n",
      "December 2021 - December 2022 (1 year 1 month)\n",
      "Riyadh, Saudi Arabia\n",
      "Enhancing and monitoring projects like churn predictions, affluent predictions,\n",
      "early warning systems, growth predictions and a recommendation system\n",
      "for potential revolving card customers using IBM Cloud Pak for Data, Oracle\n",
      "SQL, Jupyter, and IBM AutoAI, providing stakeholders with insights and\n",
      "recommendations\n",
      "Ministry of Human Resources and Social Development - KSA\n",
      "Data Migration Specialist\n",
      "December 2020 - December 2021 (1 year 1 month)\n",
      "Riyadh, Saudi Arabia\n",
      "Participated in analyzing the old database, designing the new one, and\n",
      "preparing mapping sheets for data migration\n",
      "======\n",
      "Alinma Bank: Artificial Intelligence Engineer\n",
      "December 2021 - December 2022 (1 year 1 month)\n",
      "Riyadh, Saudi Arabia\n",
      "Enhancing and monitoring projects like churn predictions, affluent predictions,\n",
      "early warning systems, growth predictions and a recommendation system\n",
      "for potential revolving card customers using IBM Cloud Pak for Data, Oracle\n",
      "SQL, Jupyter, and IBM AutoAI, providing stakeholders with insights and\n",
      "recommendations\n",
      "======\n",
      "Alinma Bank: Riyadh, KSA\n",
      "Artificial Intelligence Engineer — Contract Dec 2021 - Jan 2023\n",
      "◦ Developing AI use cases like churn predictions, affluent predictions, early warning systems, growth\n",
      "predictions and recommendation system for potential revolving card customers using IBM Cloud Pak for\n",
      "Data, Oracle SQL, Jupyter, and IBM AutoAI, providing stakeholders with insights and recommendations\n",
      "•\n",
      "======\n",
      "=================\n",
      "\n",
      "\n",
      "Query: Can we talk about your private life?\n",
      "Top matches:\n",
      "Mohamed Murad Ismail Home Know more about Me Get in Touch I'm A Data Scientist Located In Our Lovely Earth With 5 years in Data Analysis, Machine Learning, and AI, I’ve delivered solutions to major clients in Saudi Arabia, specializing in data analysis, statistics, machine learning, and deep learning, driven by a passion for leveraging data insights Waking Up I find holiness in the dawn, waking up is my daily sacrament\n",
      "======\n",
      "My name is Mohamed Murad Ismail\n",
      "======\n",
      "I have a strict healthy lifestyle\n",
      "======\n",
      "=================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query: Test 1\n",
    "query1 = \"tell me about your experience at Alinma Bank\"\n",
    "query2 = \"Can we talk about your private life?\"\n",
    "queries = [query1, query2]\n",
    "\n",
    "def print_context(query, results):\n",
    "    print(f\"Query: {query}\\nTop matches:\")\n",
    "    for result in results[\"documents\"][0]:\n",
    "        print(result+\"\\n======\")\n",
    "\n",
    "def find_context(query, top_matches=2):\n",
    "    query_emb = get_embedding([query])\n",
    "    query_emb_list = extract_embedding_list(query_emb)\n",
    "    results = collection.query(query_embeddings=query_emb_list, n_results=top_matches)\n",
    "    return results\n",
    "\n",
    "for query in queries:\n",
    "    results = find_context(query, 3)\n",
    "    print_context(query, results)\n",
    "    print(\"=================\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32ff939",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbd36860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "pushover_url = \"https://api.pushover.net/1/messages.json\"\n",
    "\n",
    "def push(message):\n",
    "    print(f\"Push: {message}\")\n",
    "    payload = {\"user\": pushover_user, \"token\": pushover_token, \"message\": message}\n",
    "    requests.post(pushover_url, data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3438411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user details\n",
    "def record_user_details(email, name=\"Name not provided\", notes=\"not provided\"):\n",
    "    push(f\"Recording interest from {name} with email {email} and notes {notes}\")\n",
    "    return {\"recorded\": \"ok\"}\n",
    "\n",
    "\n",
    "record_user_details_json = {\n",
    "    \"name\": \"record_user_details\",\n",
    "    \"description\": \"Use this tool to record that a user is interested in being in touch and provided an email address\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"email\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The email address of this user\"\n",
    "            },\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The user's name, if they provided it\"\n",
    "            }\n",
    "            ,\n",
    "            \"notes\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any additional information about the conversation that's worth recording to give context\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"email\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14d421fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown question\n",
    "def record_unknown_question(question):\n",
    "    push(f\"Recording {question} asked that I couldn't answer\")\n",
    "    return {\"recorded\": \"ok\"}\n",
    "\n",
    "record_unknown_question_json = {\n",
    "    \"name\": \"record_unknown_question\",\n",
    "    \"description\": \"Always use this tool to record any question that couldn't be answered as you didn't know the answer\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question that couldn't be answered\"\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"question\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "401b6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": record_user_details_json},\n",
    "        {\"type\": \"function\", \"function\": record_unknown_question_json}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8cbfbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls(tool_calls):\n",
    "    results = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Tool called: {tool_name}\", flush=True)\n",
    "        tool = globals().get(tool_name)\n",
    "        result = tool(**arguments) if tool else {}\n",
    "        results.append({\"role\": \"tool\",\"content\": json.dumps(result),\"tool_call_id\": tool_call.id})\n",
    "        print(\"\\n\\n\\n============\",result,\"\\n===============\\n\\n\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c996689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push: Recording this is a really hard question asked that I couldn't answer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recorded': 'ok'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[\"record_unknown_question\"](\"this is a really hard question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba1cec",
   "metadata": {},
   "source": [
    "### Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a2dca",
   "metadata": {},
   "source": [
    "### 1. Ollama models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7ba7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_system_prompt(name, context_list):\n",
    "    context = \"\"\n",
    "    for result in context_list[\"documents\"][0]:\n",
    "        context += \"- \" + result + \".\\n\\n\"\n",
    "\n",
    "    system_prompt = f\"\"\"You are representing {name} and responding to questions submitted via {name}'s website.\n",
    "    Your role is to accurately reflect {name}’s professional background, expertise, and experience, based on the provided context.\n",
    "    Respond in a clear, concise, and professional tone, suitable for potential clients, collaborators, or employers.\n",
    "\n",
    "    You are provided with verified background information to support your answers. Use it exclusively to generate accurate and helpful responses.\n",
    "    If a question falls outside the provided context or you are uncertain about the answer, log it using the 'record_unknown_question' tool.\n",
    "\n",
    "    If the user seems interested in further communication, kindly request their email and record it using the 'record_user_details' tool.\n",
    "\n",
    "    Always stay in character as {name}.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Now, using the above context, respond appropriately to the user's latest message.\n",
    "    \"\"\"\n",
    "    return system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f6ecff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Mohamed Murad Ismail\"\n",
    "query_test = \"Please tell me about your work in CST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44812ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are representing Mohamed Murad Ismail and responding to questions submitted via Mohamed Murad Ismail's website.\n",
      "    Your role is to accurately reflect Mohamed Murad Ismail’s professional background, expertise, and experience, based on the provided context.\n",
      "    Respond in a clear, concise, and professional tone, suitable for potential clients, collaborators, or employers.\n",
      "\n",
      "    You are provided with verified background information to support your answers. Use it exclusively to generate accurate and helpful responses.\n",
      "    If a question falls outside the provided context or you are uncertain about the answer, log it using the 'record_unknown_question' tool.\n",
      "\n",
      "    If the user seems interested in further communication, kindly request their email and record it using the 'record_user_details' tool.\n",
      "\n",
      "    Always stay in character as Mohamed Murad Ismail.\n",
      "\n",
      "    Context:\n",
      "    - I have also worked as a Data\n",
      "Scientist at CST and an Artificial Intelligence Engineer at Alinma\n",
      "Bank, where I developed and implemented predictive models for\n",
      "various business use cases.\n",
      "\n",
      "- Communications, Space & Technology Commission (CST): Data Scientist\n",
      "January 2023 - January 2024 (1 year 1 month)\n",
      "Riyadh, Saudi Arabia\n",
      "As a Data Scientist at CST in KSA, I spearheaded the development of three\n",
      "critical AI use cases: Fraud Detection, Phishing Detection, and Throughput\n",
      "Forecasting, leveraging advanced machine learning techniques to enhance\n",
      "security and operational efficiency..\n",
      "\n",
      "- rency, and efficiency, thereby motivating employees with\n",
      "timely and fair rewards based on their performance and contributions.\n",
      "  Page 1 of 3   \n",
      "Communications, Space & Technology Commission (CST)\n",
      "Data Scientist\n",
      "January 2023 - January 2024 (1 year 1 month)\n",
      "Riyadh, Saudi Arabia\n",
      "As a Data Scientist at CST in KSA, I spearheaded the development of three\n",
      "critical AI use cases: Fraud Detection, Phishing Detection, and Throughput\n",
      "Forecasting, leveraging advanced machine learning techniques to enhance\n",
      "security and operational efficiency.\n",
      "Alinma Bank\n",
      "Artificial Intelligence Engineer\n",
      "December 2021 - December 2022 (1 year 1 month)\n",
      "Riyadh, Saudi Arabia\n",
      "Enhancing and monitoring projects like churn predictions, affluent predictions,\n",
      "early warning systems, growth predictions and a recommendation system\n",
      "for potential revolving card customers using IBM Cloud Pak for Data, Oracle\n",
      "SQL, Jupyter, and IBM AutoAI, providing stakeholders with insights and\n",
      "recommendations\n",
      "Ministry of Human Resources and Social .\n",
      "\n",
      "\n",
      "\n",
      "    Now, using the above context, respond appropriately to the user's latest message.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# testing...\n",
    "context = find_context(query_test, 3)\n",
    "system_prompt = build_system_prompt(name, context)\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1b550d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    context = find_context(message)\n",
    "    system_prompt = build_system_prompt(name, context)\n",
    "\n",
    "    # Truncate history to last 3 turns if longer\n",
    "    history = history[-3:] if len(history) > 3 else history\n",
    "\n",
    "    # Start with full messages\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    while True:\n",
    "        response = ai_client.chat.completions.create(\n",
    "            model=qwen_model_name,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "        )\n",
    "\n",
    "        choice = response.choices[0]\n",
    "        finish_reason = choice.finish_reason\n",
    "\n",
    "        if finish_reason == \"tool_calls\":\n",
    "            tool_calls = choice.message.tool_calls\n",
    "            tool_results = handle_tool_calls(tool_calls)\n",
    "            messages.append(choice.message)\n",
    "            messages.extend(tool_results)\n",
    "        else:\n",
    "            reply = choice.message.content\n",
    "            break\n",
    "\n",
    "    # Optional: Remove <think> tags and everything before them\n",
    "    if reply and \"</think>\\n\\n\" in reply:\n",
    "        reply = reply.split(\"</think>\\n\\n\", 1)[1].strip()\n",
    "\n",
    "    # Debug logs (can be removed or replaced with logging)\n",
    "    # print(\"history:\", history)\n",
    "    # print(\"reply:\", reply)\n",
    "\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66bb1aa",
   "metadata": {},
   "source": [
    "### 2. Google (Gemeni) API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57092153",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "google_base_url = os.getenv('GOOGLE_BASE_URL')\n",
    "\n",
    "gemini_model_name = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19fde14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    context = find_context(message)\n",
    "    system_prompt = build_system_prompt(name, context)\n",
    "\n",
    "    # Truncate history to last 3 turns if longer\n",
    "    history = history[-3:] if len(history) > 3 else history\n",
    "\n",
    "    # Start with full messages\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    while True:\n",
    "        gemini = OpenAI(api_key=google_api_key, base_url=google_base_url)\n",
    "        response = gemini.chat.completions.create(model=gemini_model_name, messages=messages, tools=tools)\n",
    "\n",
    "        choice = response.choices[0]\n",
    "        finish_reason = choice.finish_reason\n",
    "\n",
    "        if finish_reason == \"tool_calls\":\n",
    "            tool_calls = choice.message.tool_calls\n",
    "            tool_results = handle_tool_calls(tool_calls)\n",
    "            messages.append(choice.message)\n",
    "            messages.extend(tool_results)\n",
    "        else:\n",
    "            reply = choice.message.content\n",
    "            break\n",
    "\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80447f02",
   "metadata": {},
   "source": [
    "### Run Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d8007564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool called: record_user_details\n",
      "Push: Recording interest from Name not provided with email test@gmail.com and notes not provided\n",
      "\n",
      "\n",
      "\n",
      "============ {'recorded': 'ok'} \n",
      "===============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.ChatInterface(chat, \n",
    "type=\"messages\",\n",
    "title=\"💼 Career Agent\",\n",
    "description=\"Mohamed Murad AI Career Avatar.\",\n",
    "submit_btn=\"Send\",\n",
    "theme=\"soft\",\n",
    "examples=[\n",
    "        [\"What is your current Job title?\"],\n",
    "        [\"How many years of experience do you have?\"],\n",
    "        [\"Do you have any technical certificates?\"],\n",
    "        [\"What is your experience in MLOps?\"],\n",
    "        [\"Talk about your recent client project?\"],\n",
    "        [\"How many clients you have worked for?\"],\n",
    "        [\"Tell me about your lifestyle?\"],\n",
    "        [\"I need to contact with you\"]]\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec160f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
